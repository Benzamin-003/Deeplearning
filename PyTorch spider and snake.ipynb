{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDhLfvb2Fwj613PdVHeQbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benzamin-003/Deeplearning/blob/main/PyTorch%20spider%20and%20snake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCR7ESCiknHi",
        "outputId": "4a976fc6-6bb7-4f12-f803-803d4965c012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your ZIP file in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "\n",
        "# Destination folder in Colab\n",
        "extract_path = '/content/images'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Extracted files to {extract_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEPEI0wJkpmT",
        "outputId": "b107f596-246a-48b8-ce35-6b834f3998eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files to /content/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes=2):  # 2 classes: snake, spider\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(16 * 32 * 32, num_classes)  # flatten size updated\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Z2KJ-dzck4Bp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "metadata": {
        "id": "Cj9sT5utlBwY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "input_size = 16_384  # after 128x128 images and 2x2 pooling\n",
        "num_classes = 2      # snake/spider\n",
        "learning_rate = 0.001\n",
        "batch_size = 32      # or 64 if memory allows\n",
        "num_epochs = 10      # increase if needed"
      ],
      "metadata": {
        "id": "w2dCpptclExO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGTXrnwXlHhj",
        "outputId": "c545486b-bcd3-4dc2-b423-26aa384b937d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ToBW:\n",
        "    def __call__(self, img):\n",
        "        # Convert PIL image to numpy array\n",
        "        img_np = np.array(img)\n",
        "        # Convert to grayscale using OpenCV\n",
        "        bw = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "        # Convert back to PIL Image\n",
        "        img_pil = Image.fromarray(bw)\n",
        "        return img_pil\n",
        "\n",
        "# Use in a transform pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    ToBW(),                # custom OpenCV B&W conversion\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "57FeJHLclJ3S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dataset_path = 'images/dataset'  # contains 'snake' and 'spider' subfolders\n",
        "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "print(f\"Classes: {full_dataset.classes}\")  # ['snake', 'spider']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3u7KgLBlLxx",
        "outputId": "6de39815-e46c-4ec8-f424-dc98ceb97b49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['snake', 'spider']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "indices = list(range(len(full_dataset)))\n",
        "labels = [full_dataset[i][1] for i in indices]\n",
        "\n",
        "train_indices, test_indices = [], []\n",
        "\n",
        "for class_label in [0, 1]:  # 0=snake, 1=spider\n",
        "    class_indices = [i for i, l in enumerate(labels) if l == class_label]\n",
        "\n",
        "    # train_test_split to select fixed numbers\n",
        "    train_idx, test_idx = train_test_split(\n",
        "        class_indices, train_size=2400, test_size=200, random_state=42, shuffle=True\n",
        "    )\n",
        "    train_indices += train_idx\n",
        "    test_indices += test_idx\n",
        ""
      ],
      "metadata": {
        "id": "OchhXWZPlN6L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = Subset(full_dataset, train_indices)\n",
        "test_dataset = Subset(full_dataset, test_indices)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCqNjYVFlPvX",
        "outputId": "49ca470f-5360-4b2d-c5db-fd6c0e0dfc96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 4800, Test samples: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(in_channels =1, num_classes=num_classes).to(device)\n"
      ],
      "metadata": {
        "id": "3-yHM8RulTqm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1Hy0bhCTlXN7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "    for batch_index, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        #move data and targets to the device (GPU/CPU)\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        #forward pass: compute the model output\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        #backward pass: compute the gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        #optimization step: update the model parameters\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU2JdmvklZJw",
        "outputId": "0e1f0a66-2bd0-4e10-d442-ce50ce72f495"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [01:00<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:56<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:55<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def check_accuracy(loader, model, loader_name=\"Data\"):\n",
        "    print(f\"Checking accuracy on {loader_name}\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # evaluation mode\n",
        "\n",
        "    with torch.no_grad():  # no gradient needed\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum().item()  # convert to number\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    accuracy = 100 * num_correct / num_samples\n",
        "    print(f\"Got {num_correct}/{num_samples} correct -> Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    model.train()  # back to training mode\n",
        "\n",
        "# Usage\n",
        "check_accuracy(train_loader, model, loader_name=\"Training Data\")\n",
        "check_accuracy(test_loader, model, loader_name=\"Test Data\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUY8N1nRlbvW",
        "outputId": "acbbf536-b9e7-447f-fcea-a14dbe37175f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on Training Data\n",
            "Got 4165/4800 correct -> Accuracy: 86.77%\n",
            "Checking accuracy on Test Data\n",
            "Got 300/400 correct -> Accuracy: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wt9rfUf1lsDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}